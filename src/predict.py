# -*- coding: utf-8 -*-
"""predict.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mBjZPOVElaCNkDmolD3C2MwlV8z8Mv60
"""

import os
import tensorflow as tf
import numpy as np
import pandas as pd
import joblib

BASE_DIR = os.path.dirname(os.path.dirname(__file__))

# Rebuild the same architecture you trained in Colab
model = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(20,)),
    tf.keras.layers.Dense(64, activation="relu"),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(32, activation="relu"),
    tf.keras.layers.Dense(1, activation="sigmoid"),
])

# Load weights
model.load_weights(os.path.join(BASE_DIR, "models", "credit_weights.weights.h5"))

# Load preprocessing artifacts
artifacts = joblib.load(os.path.join(BASE_DIR, "artifacts/preprocess.pkl"))
cat_cols = artifacts["cat_cols"]
num_cols = artifacts["num_cols"]
encoders = artifacts["encoders"]
scaler = artifacts["scaler"]



# Example: multiple raw inputs
raw_inputs = [
    {
        "account_status": "A11", "months": 6, "credit_history": "A34", "purpose": "A43",
        "credit_amount": 1169, "savings": "A65", "employment": "A75", "installment_rate": 4,
        "personal_status": "A93", "guarantors": "A101", "residence": 4, "property": "A121",
        "age": 67, "other_installments": "A143", "housing": "A152", "credit_cards": 2,
        "job": "A173", "dependents": 1, "phone": "A192", "foreign_worker": "A201"
    },
    {
        "account_status": "A12", "months": 24, "credit_history": "A32", "purpose": "A40",
        "credit_amount": 2500, "savings": "A61", "employment": "A73", "installment_rate": 2,
        "personal_status": "A92", "guarantors": "A101", "residence": 2, "property": "A122",
        "age": 35, "other_installments": "A141", "housing": "A151", "credit_cards": 1,
        "job": "A172", "dependents": 2, "phone": "A191", "foreign_worker": "A201"
    }
]


# Convert to DataFrame
df_input = pd.DataFrame(raw_inputs)

# Apply encoders to categorical columns
for c in cat_cols:
    le = encoders[c]
    df_input[c] = le.transform(df_input[c])

# Scale numeric columns
df_input[num_cols] = scaler.transform(df_input[num_cols])

# Final feature array
samples = df_input.values.astype(np.float32)

# Predict
probs = model.predict(samples).ravel()
classes = (probs >= 0.5).astype(int)

# Show results
print("TF version:", tf.__version__)
for i, raw in enumerate(raw_inputs):
    print(f"\nInput {i+1}: {raw}")
    print(f"Preprocessed: {samples[i].tolist()}")
    print(f"Probability: {probs[i]:.4f}, Class: {classes[i]}")